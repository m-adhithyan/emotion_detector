{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a11c71e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "model = load_model('best_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9d2e225a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D , MaxPooling2D , Flatten, Dense,Dropout,BatchNormalization\n",
    "from PIL import Image,ImageOps,ImageEnhance\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('dark_background')\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils import to_categorical, plot_model\n",
    "from sklearn.utils import class_weight\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7facdcd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rotate(img,angle):\n",
    "    return img.rotate(angle=angle)\n",
    "\n",
    "def flip(img):\n",
    "    return ImageOps.mirror(img)\n",
    "\n",
    "def change_brightness(img,factor = 1.2):\n",
    "    enhancer = ImageEnhance.Brightness(img)\n",
    "    return enhancer.enhance(factor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eca81f8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8d5eb665",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final data shape: (9062, 48, 48, 1)\n",
      "Final result shape: (9062, 7)\n",
      "Class counts after augmentation: Counter({np.int64(6): 2493, np.int64(3): 1774, np.int64(5): 1247, np.int64(4): 1233, np.int64(2): 1024, np.int64(0): 958, np.int64(1): 333})\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "le.fit(['angry', 'disgusted', 'fearful', 'happy', 'neutral', 'sad', 'surprised'])\n",
    "\n",
    "data = []\n",
    "result = []\n",
    "\n",
    "for emotion in ['angry', 'disgusted', 'fearful', 'happy', 'neutral', 'sad', 'surprised']:\n",
    "    class_index = le.transform([emotion])[0]\n",
    "    class_label = to_categorical(class_index, num_classes=7)\n",
    "\n",
    "    paths = []\n",
    "    for r, d, f in os.walk(os.path.join(r\"C:\\Users\\USER\\Desktop\\dataset\\test\", emotion)):\n",
    "        for file in f:\n",
    "            if file.lower().endswith((\".jpg\", \"jpeg\", \".png\")):\n",
    "                paths.append(os.path.join(r, file))\n",
    "\n",
    "    for path in paths:\n",
    "        pil_img = Image.open(path).convert('L').resize((48, 48))\n",
    "\n",
    "        arr_img = np.expand_dims(np.array(pil_img).astype('float32') / 255.0, -1)\n",
    "        if arr_img.shape == (48, 48, 1):\n",
    "            data.append(arr_img)\n",
    "            result.append(class_label)\n",
    "\n",
    "        if emotion in ['disgusted', 'surprised']:\n",
    "            flipped = ImageOps.mirror(pil_img)\n",
    "            flipped_arr = np.expand_dims(np.array(flipped).astype('float32') / 255.0, -1)\n",
    "            data.append(flipped_arr)\n",
    "            result.append(class_label)\n",
    "\n",
    "            rotated = pil_img.rotate(15)\n",
    "            rotated_arr = np.expand_dims(np.array(rotated).astype('float32') / 255.0, -1)\n",
    "            data.append(rotated_arr)\n",
    "            result.append(class_label)\n",
    "\n",
    "data = np.array(data)\n",
    "result = np.array(result)\n",
    "\n",
    "\n",
    "print(\"Final data shape:\", data.shape)\n",
    "print(\"Final result shape:\", result.shape)\n",
    "\n",
    "y_ints = np.argmax(result, axis=1)\n",
    "print(\"Class counts after augmentation:\", Counter(y_ints))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8b6caea2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9062, 7)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = result.reshape(-1,7)\n",
    "result.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "532c54ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1d9e3ac7e20>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(data[6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "34514690",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class weights (by index):\n",
      "{0: np.float64(1.3513271696987772), 1: np.float64(3.8876018876018876), 2: np.float64(1.2642299107142858), 3: np.float64(0.7297471412465776), 4: np.float64(1.0499362762136484), 5: np.float64(1.0381486997365106), 6: np.float64(0.5192825626038623)}\n"
     ]
    }
   ],
   "source": [
    "weights = class_weight.compute_class_weight(\n",
    "    class_weight='balanced',\n",
    "    classes=np.unique(y_ints),\n",
    "    y=y_ints\n",
    ")\n",
    "class_weights = dict(enumerate(weights))\n",
    "print(\"Class weights (by index):\")\n",
    "print(class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a99ce225",
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain, xtest, ytrain, ytest = train_test_split(data, result, test_size=0.2, random_state=42,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "10d47ea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.losses import CategoricalCrossentropy\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "loss_fn = CategoricalCrossentropy(label_smoothing=0.1)\n",
    "\n",
    "model.compile(\n",
    "    optimizer=Adam(learning_rate=3e-4),\n",
    "    loss=loss_fn,\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb1907a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "checkpoint = ModelCheckpoint(\n",
    "    filepath='best_model_v2.h5',  \n",
    "    monitor='val_loss',         \n",
    "    save_best_only=True,        \n",
    "    verbose=1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9df80394",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "early_stop = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience = 7,                \n",
    "    restore_best_weights=True,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "831080d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau(\n",
    "    monitor='val_loss',\n",
    "    factor=0.5,\n",
    "    patience=3,\n",
    "    verbose=1,\n",
    "    min_lr=1e-6\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9eef1b04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 305ms/step - accuracy: 0.6123 - loss: 1.3541\n",
      "Epoch 1: val_loss improved from inf to 1.23457, saving model to best_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 323ms/step - accuracy: 0.6123 - loss: 1.3541 - val_accuracy: 0.6431 - val_loss: 1.2346 - learning_rate: 3.0000e-04\n",
      "Epoch 2/20\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 298ms/step - accuracy: 0.6287 - loss: 1.2951\n",
      "Epoch 2: val_loss did not improve from 1.23457\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 312ms/step - accuracy: 0.6287 - loss: 1.2952 - val_accuracy: 0.6420 - val_loss: 1.2498 - learning_rate: 3.0000e-04\n",
      "Epoch 3/20\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 303ms/step - accuracy: 0.6503 - loss: 1.2756\n",
      "Epoch 3: val_loss did not improve from 1.23457\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 317ms/step - accuracy: 0.6503 - loss: 1.2756 - val_accuracy: 0.6376 - val_loss: 1.2371 - learning_rate: 3.0000e-04\n",
      "Epoch 4/20\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 301ms/step - accuracy: 0.6495 - loss: 1.2628\n",
      "Epoch 4: val_loss improved from 1.23457 to 1.20437, saving model to best_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 317ms/step - accuracy: 0.6495 - loss: 1.2629 - val_accuracy: 0.6591 - val_loss: 1.2044 - learning_rate: 3.0000e-04\n",
      "Epoch 5/20\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 300ms/step - accuracy: 0.6563 - loss: 1.2494\n",
      "Epoch 5: val_loss improved from 1.20437 to 1.12795, saving model to best_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 316ms/step - accuracy: 0.6562 - loss: 1.2494 - val_accuracy: 0.6966 - val_loss: 1.1280 - learning_rate: 3.0000e-04\n",
      "Epoch 6/20\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 298ms/step - accuracy: 0.6607 - loss: 1.2293\n",
      "Epoch 6: val_loss did not improve from 1.12795\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 312ms/step - accuracy: 0.6607 - loss: 1.2293 - val_accuracy: 0.6343 - val_loss: 1.2495 - learning_rate: 3.0000e-04\n",
      "Epoch 7/20\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 307ms/step - accuracy: 0.6623 - loss: 1.2147\n",
      "Epoch 7: val_loss improved from 1.12795 to 1.09995, saving model to best_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 323ms/step - accuracy: 0.6623 - loss: 1.2148 - val_accuracy: 0.7192 - val_loss: 1.0999 - learning_rate: 3.0000e-04\n",
      "Epoch 8/20\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 299ms/step - accuracy: 0.6915 - loss: 1.1832\n",
      "Epoch 8: val_loss did not improve from 1.09995\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 313ms/step - accuracy: 0.6914 - loss: 1.1833 - val_accuracy: 0.7104 - val_loss: 1.1176 - learning_rate: 3.0000e-04\n",
      "Epoch 9/20\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 360ms/step - accuracy: 0.6827 - loss: 1.1841\n",
      "Epoch 9: val_loss did not improve from 1.09995\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 379ms/step - accuracy: 0.6827 - loss: 1.1841 - val_accuracy: 0.6977 - val_loss: 1.1026 - learning_rate: 3.0000e-04\n",
      "Epoch 10/20\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 380ms/step - accuracy: 0.6948 - loss: 1.1805\n",
      "Epoch 10: val_loss did not improve from 1.09995\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 398ms/step - accuracy: 0.6948 - loss: 1.1805 - val_accuracy: 0.6856 - val_loss: 1.1531 - learning_rate: 3.0000e-04\n",
      "Epoch 11/20\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 458ms/step - accuracy: 0.6876 - loss: 1.1722\n",
      "Epoch 11: val_loss improved from 1.09995 to 1.06611, saving model to best_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 480ms/step - accuracy: 0.6876 - loss: 1.1721 - val_accuracy: 0.7204 - val_loss: 1.0661 - learning_rate: 3.0000e-04\n",
      "Epoch 12/20\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 410ms/step - accuracy: 0.7074 - loss: 1.1427\n",
      "Epoch 12: val_loss did not improve from 1.06611\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 426ms/step - accuracy: 0.7074 - loss: 1.1428 - val_accuracy: 0.6718 - val_loss: 1.1816 - learning_rate: 3.0000e-04\n",
      "Epoch 13/20\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 344ms/step - accuracy: 0.7167 - loss: 1.1306\n",
      "Epoch 13: val_loss did not improve from 1.06611\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 361ms/step - accuracy: 0.7167 - loss: 1.1308 - val_accuracy: 0.7165 - val_loss: 1.1138 - learning_rate: 3.0000e-04\n",
      "Epoch 14/20\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 350ms/step - accuracy: 0.7172 - loss: 1.1102\n",
      "Epoch 14: val_loss improved from 1.06611 to 1.04764, saving model to best_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 368ms/step - accuracy: 0.7172 - loss: 1.1103 - val_accuracy: 0.7424 - val_loss: 1.0476 - learning_rate: 3.0000e-04\n",
      "Epoch 15/20\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 348ms/step - accuracy: 0.7195 - loss: 1.1160\n",
      "Epoch 15: val_loss improved from 1.04764 to 1.04009, saving model to best_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 367ms/step - accuracy: 0.7195 - loss: 1.1160 - val_accuracy: 0.7452 - val_loss: 1.0401 - learning_rate: 3.0000e-04\n",
      "Epoch 16/20\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 355ms/step - accuracy: 0.7320 - loss: 1.1053\n",
      "Epoch 16: val_loss did not improve from 1.04009\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 371ms/step - accuracy: 0.7320 - loss: 1.1054 - val_accuracy: 0.7352 - val_loss: 1.0488 - learning_rate: 3.0000e-04\n",
      "Epoch 17/20\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 397ms/step - accuracy: 0.7342 - loss: 1.1033\n",
      "Epoch 17: val_loss improved from 1.04009 to 1.03568, saving model to best_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 415ms/step - accuracy: 0.7342 - loss: 1.1033 - val_accuracy: 0.7369 - val_loss: 1.0357 - learning_rate: 3.0000e-04\n",
      "Epoch 18/20\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 349ms/step - accuracy: 0.7431 - loss: 1.0796\n",
      "Epoch 18: val_loss improved from 1.03568 to 0.99285, saving model to best_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 366ms/step - accuracy: 0.7431 - loss: 1.0797 - val_accuracy: 0.7744 - val_loss: 0.9928 - learning_rate: 3.0000e-04\n",
      "Epoch 19/20\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 349ms/step - accuracy: 0.7422 - loss: 1.0762\n",
      "Epoch 19: val_loss did not improve from 0.99285\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 363ms/step - accuracy: 0.7422 - loss: 1.0763 - val_accuracy: 0.7380 - val_loss: 1.0675 - learning_rate: 3.0000e-04\n",
      "Epoch 20/20\n",
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 312ms/step - accuracy: 0.7573 - loss: 1.0477\n",
      "Epoch 20: val_loss improved from 0.99285 to 0.97804, saving model to best_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m142/142\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 327ms/step - accuracy: 0.7572 - loss: 1.0479 - val_accuracy: 0.7750 - val_loss: 0.9780 - learning_rate: 3.0000e-04\n",
      "Restoring model weights from the end of the best epoch: 20.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x1d9e30ecb20>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "    data, result,\n",
    "    validation_data=(xtest, ytest), \n",
    "    batch_size=64,\n",
    "    epochs=20,\n",
    "    callbacks=[checkpoint, early_stop, reduce_lr],\n",
    "    class_weight=class_weights\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ab1e8cd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 29ms/step - accuracy: 0.7615 - loss: 0.9869\n",
      "Test Accuracy:  0.774958610534668\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model.evaluate(xtest, ytest)\n",
    "\n",
    "print('Test Accuracy: ', test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e3015c62",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "model.save('model_v2.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "049bce9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "model = load_model('model_v2.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "697357c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.losses import CategoricalCrossentropy\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "model.compile(\n",
    "    optimizer=Adam(learning_rate=5e-5),  # ⬅️ lower LR for fine-tuning\n",
    "    loss=CategoricalCrossentropy(label_smoothing=0.1),\n",
    "    metrics=['accuracy']\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "30435acd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    data, result,\n",
    "    test_size=0.1,\n",
    "    random_state=42,\n",
    "    stratify=np.argmax(result, axis=1)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2b6d2046",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import class_weight\n",
    "\n",
    "class_weights = class_weight.compute_class_weight(\n",
    "    class_weight='balanced',\n",
    "    classes=np.unique(np.argmax(y_train, axis=1)),\n",
    "    y=np.argmax(y_train, axis=1)\n",
    ")\n",
    "class_weights = dict(enumerate(class_weights))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d8e5550",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "\n",
    "checkpoint = ModelCheckpoint('final_model_finetuned.keras', monitor='val_loss', save_best_only=True)\n",
    "early_stop = EarlyStopping(monitor='val_loss', patience=6, restore_best_weights=True)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', patience=3, factor=0.5, min_lr=1e-6, verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "45b89858",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 285ms/step - accuracy: 0.7635 - loss: 1.0514 - val_accuracy: 0.8401 - val_loss: 0.8784 - learning_rate: 5.0000e-05\n",
      "Epoch 2/30\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 326ms/step - accuracy: 0.7665 - loss: 1.0193 - val_accuracy: 0.8434 - val_loss: 0.8749 - learning_rate: 5.0000e-05\n",
      "Epoch 3/30\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 312ms/step - accuracy: 0.7681 - loss: 1.0212 - val_accuracy: 0.8302 - val_loss: 0.8988 - learning_rate: 5.0000e-05\n",
      "Epoch 4/30\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 317ms/step - accuracy: 0.7649 - loss: 1.0263 - val_accuracy: 0.8379 - val_loss: 0.8742 - learning_rate: 5.0000e-05\n",
      "Epoch 5/30\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 313ms/step - accuracy: 0.7792 - loss: 1.0173 - val_accuracy: 0.8479 - val_loss: 0.8655 - learning_rate: 5.0000e-05\n",
      "Epoch 6/30\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 309ms/step - accuracy: 0.7815 - loss: 1.0047 - val_accuracy: 0.8225 - val_loss: 0.9091 - learning_rate: 5.0000e-05\n",
      "Epoch 7/30\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 305ms/step - accuracy: 0.7798 - loss: 1.0029 - val_accuracy: 0.8280 - val_loss: 0.8807 - learning_rate: 5.0000e-05\n",
      "Epoch 8/30\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 299ms/step - accuracy: 0.7806 - loss: 0.9916\n",
      "Epoch 8: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 307ms/step - accuracy: 0.7806 - loss: 0.9917 - val_accuracy: 0.8379 - val_loss: 0.8744 - learning_rate: 5.0000e-05\n",
      "Epoch 9/30\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 307ms/step - accuracy: 0.7727 - loss: 1.0124 - val_accuracy: 0.8313 - val_loss: 0.8799 - learning_rate: 2.5000e-05\n",
      "Epoch 10/30\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 307ms/step - accuracy: 0.7728 - loss: 1.0048 - val_accuracy: 0.8313 - val_loss: 0.8816 - learning_rate: 2.5000e-05\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_val, y_val),\n",
    "    batch_size=64,\n",
    "    epochs=30,\n",
    "    class_weight=class_weights,\n",
    "    callbacks=[checkpoint, early_stop, reduce_lr],\n",
    "    shuffle=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8ddffa08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - accuracy: 0.8535 - loss: 0.8399\n",
      "Test Accuracy:  0.8478500843048096\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model.evaluate(X_val, y_val)\n",
    "\n",
    "print('Test Accuracy: ', test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90c28eae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
